{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2496527-3c62-4e4c-ac43-e09cbf152c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2499c7d5-d68c-4d70-9df4-2a726218523b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/windact/cloud_detection/notebooks')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4df6ba3a-3b7b-44d0-9988-a0a11eacb77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/windact/cloud_detection')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd().parent.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4a33f7-0785-4eac-94e2-d37f79e99cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc72e1d-e9b5-4be1-be4b-eb8ce5981539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/windact/cloud_detection/cloudnet-package')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PACKAGE_DIR = Path.cwd().parent.resolve() / \"cloudnet-package\"\n",
    "PACKAGE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be620e83-4b3f-4800-a980-8685caa95e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/windact/cloud_detection/cloudnet-package/trainer')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINER_DIR = PACKAGE_DIR / \"trainer\"\n",
    "TRAINER_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a233bc61-78c1-4162-8d5d-b8be87a84450",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAINER_DIR.exists():\n",
    "    TRAINER_DIR.mkdir(exist_ok= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96dd3496-890e-47d8-9a3a-663a8c3844ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch /home/windact/cloud_detection/cloudnet-package/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4ec5c26-4724-42c4-8fcc-1f0409358e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8740e25-b0cd-4498-99b4-9b11ed558360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/windact/cloud_detection/cloudnet-package/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/windact/cloud_detection/cloudnet-package/requirements.txt\n",
    "tensorflow>=2.6.2,<2.7.0\n",
    "tensorflow-addons>=0.14.0,<0.15.0\n",
    "tensorflow-io>=0.21.0,<0.22.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0099df6-b48c-4688-b545-8bb3626da272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/windact/cloud_detection/cloudnet-package/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/windact/cloud_detection/cloudnet-package/setup.py\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Packages that are required for this module to be executed\n",
    "#here = os.path.abspath(os.path.dirname(__file__))\n",
    "#lib_path = Path.cwd().resolve() / 'requirements.txt'\n",
    "\n",
    "# def list_reqs(fname=\"f.txt\"):\n",
    "#     with open(fname) as fd:\n",
    "#         return fd.read().splitlines()\n",
    "\n",
    "# with open(\"requirements.txt\", \"r\") as f:\n",
    "#     rq = f.read().splitlines()\n",
    "\n",
    "# REQUIRED_PACKAGES = ['pandas<=1.3.5','tensorflow<=2.6.2','tensorflow-io<=0.23.1','tensorflow-addons<=0.15.0']\n",
    "\n",
    "REQUIRED_PACKAGES = ['pandas>=1.1.5,<1.2.0','tensorflow>=2.6.2,<2.7.0','tensorflow-addons>=0.14.0,<0.15.0','tensorflow-io>=0.21.0,<0.22.0']\n",
    "\n",
    "#print(\"*-*-*-*-*-*-*-*-HERE*-*-*-*-*-*-*---*\")\n",
    "#here = os.path.abspath(os.path.dirname(__file__))\n",
    "#print(lib_path)\n",
    "#REQUIRED_PACKAGES = ['some_PyPI_package>=1.0']\n",
    "\n",
    "setup(\n",
    "    name='trainer',\n",
    "    version='0.1',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='My training application package.'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58d4c8c9-6768-4691-b8a0-696734db9f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization,\\\n",
    "#     Activation, Dropout\n",
    "# from tensorflow import  keras\n",
    "\n",
    "# from pathlib import Path\n",
    "# import argparse\n",
    "# import sys\n",
    "# import logging\n",
    "\n",
    "# from datetime import datetime\n",
    "# import pandas as pd\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping,TensorBoard\n",
    "\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow import keras\n",
    "\n",
    "# import tensorflow_addons as tfa\n",
    "# import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e650063b-3ac7-49ba-95ba-44dd01113596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow\n",
    "# pandas\n",
    "# tensorflow_addons\n",
    "# tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "203463df-bd70-412b-9392-0b7c8df9df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "# import tensorflow_addons as tfa\n",
    "# import tensorflow_io as tfio\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ddbba51-5a8f-4128-a771-657641cca85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b460a8a3-ab26-47a8-acc1-777bbf4d4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e556ff6-95b3-449e-be97-349f1507627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/windact/cloud_detection/cloudnet-package/trainer/pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/windact/cloud_detection/cloudnet-package/trainer/pipeline.py\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "IMG_HEIGHT = tf.constant(192, dtype=tf.int32)\n",
    "IMG_WIDTH = tf.constant(192,dtype=tf.int32)\n",
    "EPOCHS  = 2\n",
    "\n",
    "@tf.function\n",
    "def load_image(img_path):\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tfio.experimental.image.decode_tiff(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def parser(row_csv):\n",
    "    # decoding the csv file\n",
    "    chip_id,B02_path,B03_path,B04_path,B08_path,label_path = tf.io.decode_csv(records = row_csv, record_defaults = [\"chip_id\",\"B02_path\",\"B03_path\",\"B04_path\",\"B08_path\",\"label_path\"], field_delim=';')\n",
    "    \n",
    "    B02_img = load_image(B02_path)\n",
    "    # B02_img = B02_img[:,:,0]\n",
    "    # B02_img = tf.expand_dims(B02_img, axis = -1, name=None)\n",
    "    \n",
    "    B03_img = load_image(B03_path)\n",
    "    # B03_img = B03_img[:,:,0]\n",
    "    # B03_img = tf.expand_dims(B03_img, axis = -1, name=None)\n",
    "    \n",
    "    B04_img = load_image(B04_path)\n",
    "    # B04_img = B04_img[:,:,0]\n",
    "    # B04_img = tf.expand_dims(B04_img, axis = -1, name=None)\n",
    "    \n",
    "    B08_img = load_image(B08_path)\n",
    "    # B08_img = B08_img[:,:,0]\n",
    "    # B08_img = tf.expand_dims(B08_img, axis = -1, name=None)\n",
    "    \n",
    "    image = tf.concat([B02_img,B03_img,B04_img,B08_img], axis = -1)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32, saturate=False)\n",
    "    \n",
    "    label = load_image(label_path)\n",
    "    # label = label[:,:,0]\n",
    "    # label = tf.expand_dims(label, axis = -1, name=None)\n",
    "    \n",
    "    label = tf.image.convert_image_dtype(label, dtype=tf.float32, saturate=False)\n",
    "    \n",
    "    \n",
    "    return image, label\n",
    "\n",
    "@tf.function\n",
    "def img_reshape(img,msk):\n",
    "    img_o = tf.image.resize(img,(192, 192),preserve_aspect_ratio=False)\n",
    "    msk_o = tf.image.resize(msk,(192, 192),preserve_aspect_ratio=False)\n",
    "    \n",
    "    return img_o,msk_o\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "def rotate_clk_img_and_msk(img, msk):\n",
    "    angles_tensor = tf.constant([4, 6, 8, 10, 12, 14, 16, 18, 20], dtype=tf.float32)\n",
    "    angle = tf.random.shuffle(angles_tensor)[0]\n",
    "    # Image\n",
    "    img_o = tfa.image.rotate(images = img,angles = angle,interpolation = \"nearest\",fill_mode = \"reflect\",fill_value = 0.0)\n",
    "    # Label\n",
    "    msk_o = tfa.image.rotate(images = msk,angles = angle,interpolation = \"nearest\",fill_mode = \"reflect\",fill_value = 0.0)\n",
    "    \n",
    "    return img_o, msk_o\n",
    "\n",
    "@tf.function\n",
    "def rotate_cclk_img_and_msk(img, msk):\n",
    "    angles_tensor = tf.constant([-20, -18, -16, -14, -12, -10, -8, -6, -4],dtype=tf.float32)\n",
    "    angle = tf.random.shuffle(angles_tensor)[0]\n",
    "    # Image\n",
    "    img_o = tfa.image.rotate(images = img,angles = angle,interpolation = \"nearest\",fill_mode = \"reflect\",fill_value = 0.0)\n",
    "    # Label\n",
    "    msk_o = tfa.image.rotate(images = msk,angles = angle,interpolation = \"nearest\",fill_mode = \"reflect\",fill_value = 0.0)\n",
    "    \n",
    "    return img_o, msk_o\n",
    "\n",
    "@tf.function\n",
    "def flipping_img_and_msk(img, msk):\n",
    "    img_o = tf.image.flip_left_right(img)\n",
    "    img_o = tf.image.flip_up_down(img)\n",
    "    \n",
    "    msk_o = tf.image.flip_left_right(msk)\n",
    "    msk_o = tf.image.flip_up_down(msk)\n",
    "    \n",
    "    return img_o,msk_o\n",
    "\n",
    "\n",
    "    \n",
    "@tf.function\n",
    "def zoom_img_and_msk(img, msk,height = 512,width = 512):\n",
    "\n",
    "    zoom_factor_tensor = tf.constant([1.2, 1.5, 1.8, 2, 2.2, 2.5], dtype=tf.float32)  # currently doesn't have zoom out!\n",
    "    zoom_factor = tf.random.shuffle(zoom_factor_tensor)[0]\n",
    "    # print(\"*-*-*-*-*-*\")\n",
    "    # print(img.shape)\n",
    "    #h,w,c = img.shape\n",
    "    # h = height\n",
    "    # w = width\n",
    "    h = tf.cast(height,dtype= tf.int32)\n",
    "    w = tf.cast(width,dtype= tf.int32)\n",
    "    \n",
    "    # img = tf.cast(img, dtype=tf.float32)\n",
    "    # msk = tf.cast(msk, dtype=tf.float32)\n",
    "    \n",
    "\n",
    "    # width and height of the zoomed image\n",
    "    zh = tf.math.multiply(zoom_factor, tf.cast(h, dtype=tf.float32))\n",
    "    zh = tf.cast(zh,dtype= tf.int32)\n",
    "    \n",
    "    zw = tf.math.multiply(zoom_factor, tf.cast(w, dtype=tf.float32))\n",
    "    zw = tf.cast(zw,dtype= tf.int32)\n",
    "    \n",
    "    # zh = int(np.round(zoom_factor * h))\n",
    "    # zw = int(np.round(zoom_factor * w))\n",
    "\n",
    "    img = tf.image.resize(img,(zh, zw),preserve_aspect_ratio=False)\n",
    "    msk = tf.image.resize(msk,(zh, zw),preserve_aspect_ratio=False)\n",
    "    \n",
    "    region_tensor = tf.constant([0, 1, 2, 3, 4],dtype= tf.float32)\n",
    "    region = tf.random.shuffle(region_tensor)[0]\n",
    "\n",
    "    # zooming out\n",
    "    # tf.print(\"before zoom\")\n",
    "    # tf.print(img.dtype)\n",
    "    \n",
    "    if tf.math.less_equal(zoom_factor, tf.constant(1, dtype= tf.float32)):\n",
    "        outimg = img\n",
    "        outmsk = msk\n",
    "        \n",
    "        # tf.print(\"zoom 1\")\n",
    "        # tf.print(img.dtype)\n",
    "\n",
    "    # zooming in\n",
    "    # else:\n",
    "    #     # Initializing\n",
    "    #     outimg = tf.zeros_like(img, dtype=tf.float32, name=None)\n",
    "    #     outmsk = tf.zeros_like(msk, dtype=tf.float32, name=None)\n",
    "        # bounding box of the clipped region within the input array\n",
    "    elif tf.math.equal(region, tf.constant(0,dtype= tf.float32)):\n",
    "        outimg = img[0:h, 0:w,:]\n",
    "        outmsk = msk[0:h, 0:w,:]\n",
    "        \n",
    "        # tf.print(\"zoom 0\")\n",
    "        # tf.print(img.dtype)\n",
    "        \n",
    "    elif tf.math.equal(region, tf.constant(1,dtype= tf.float32)):\n",
    "        outimg = img[0:h, zw - w:zw,:]\n",
    "        outmsk = msk[0:h, zw - w:zw,:]\n",
    "        \n",
    "        # tf.print(\"zoom 11\")\n",
    "        # tf.print(img.dtype)\n",
    "        \n",
    "    elif tf.math.equal(region, tf.constant(2,dtype= tf.float32)):\n",
    "        outimg = img[zh - h:zh, 0:w,:]\n",
    "        outmsk = msk[zh - h:zh, 0:w,:]\n",
    "        \n",
    "        # tf.print(\"zoom 2\")\n",
    "        # tf.print(img.dtype)\n",
    "        \n",
    "    elif tf.math.equal(region, tf.constant(3,dtype= tf.float32)):\n",
    "        outimg = img[zh - h:zh, zw - w:zw,:]\n",
    "        outmsk = msk[zh - h:zh, zw - w:zw,:]\n",
    "        \n",
    "        # tf.print(\"zoom 3\")\n",
    "        # tf.print(img.dtype)\n",
    "        \n",
    "    # if tf.math.equal(region, tf.constant(4,dtype= tf.float32)):\n",
    "\n",
    "    else:\n",
    "        # tf.print(\"zoom 4\")\n",
    "        # tf.print(img.dtype)\n",
    "        \n",
    "        marh = tf.math.floordiv( h, tf.constant(2))\n",
    "        marw = tf.math.floordiv( w, tf.constant(2))\n",
    "\n",
    "        zh_div = tf.math.floordiv( zh, tf.constant(2))\n",
    "        zw_div = tf.math.floordiv( zw, tf.constant(2))\n",
    "\n",
    "        zh_div_add = tf.math.add( zh_div, marh)\n",
    "        zh_div_minus = tf.math.subtract( zh_div, marh)\n",
    "\n",
    "        zw_div_add = tf.math.add( zw_div, marw)\n",
    "        zw_div_minus = tf.math.subtract( zw_div, marw)\n",
    "\n",
    "        outimg = img[zh_div_minus:zw_div_add, zw_div_minus:zw_div_add,:]\n",
    "        outmsk = msk[zh_div_minus:zw_div_add, zw_div_minus:zw_div_add,:]\n",
    "\n",
    "        # outimg = img[(zh // 2 - marh):(zh // 2 + marh), (zw // 2 - marw):(zw // 2 + marw),:]\n",
    "        # outmsk = msk[(zh // 2 - marh):(zh // 2 + marh), (zw // 2 - marw):(zw // 2 + marw),:]\n",
    "\n",
    "    # to make sure the output is in the same size of the input\n",
    "    img_o = tf.image.resize(outimg,(h, w),preserve_aspect_ratio=False)\n",
    "    msk_o = tf.image.resize(outmsk,(h, w),preserve_aspect_ratio=False)\n",
    "    return img_o, msk_o\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def data_augmentation(img, msk):\n",
    "    \n",
    "    coin_rotate_clk_img_and_msk = tf.random.uniform(shape = (1,1), minval=0, maxval=1, dtype=tf.dtypes.float32, seed=None, name=None)\n",
    "    coin_rotate_cclk_img_and_msk = tf.random.uniform(shape = (1,1), minval=0, maxval=1, dtype=tf.dtypes.float32, seed=None, name=None)\n",
    "    coin_flipping_img_and_msk = tf.random.uniform(shape = (1,1), minval=0, maxval=1, dtype=tf.dtypes.float32, seed=None, name=None)\n",
    "    coin_zoom_img_and_msk = tf.random.uniform(shape = (1,1), minval=0, maxval=1, dtype=tf.dtypes.float32, seed=None, name=None)\n",
    "\n",
    "    # rotate_clk_img_and_msk\n",
    "    if tf.math.greater_equal(coin_rotate_clk_img_and_msk, tf.constant(0.5)):\n",
    "        # tf.print(tf.constant(\"rotate_clk_img_and_msk\"))\n",
    "        # tf.print(coin_rotate_clk_img_and_msk)\n",
    "        img,msk = rotate_clk_img_and_msk(img, msk)\n",
    "    \n",
    "    # rotate_cclk_img_and_msk\n",
    "    if tf.math.greater_equal(coin_rotate_cclk_img_and_msk, tf.constant(0.5)):\n",
    "        # tf.print(tf.constant(\"rotate_cclk_img_and_msk\"))\n",
    "        # tf.print(coin_rotate_cclk_img_and_msk)\n",
    "        img,msk = rotate_cclk_img_and_msk(img, msk)\n",
    "        \n",
    "    # flipping_img_and_msk\n",
    "    # rotate_cclk_img_and_msk\n",
    "    if tf.math.greater_equal(coin_flipping_img_and_msk, tf.constant(0.5)):\n",
    "        # tf.print(tf.constant(\"flipping_img_and_msk\"))\n",
    "        # tf.print(coin_flipping_img_and_msk)\n",
    "        img,msk = flipping_img_and_msk(img, msk)\n",
    "    \n",
    "    # zoom_img_and_msk\n",
    "    if tf.math.greater_equal(coin_zoom_img_and_msk, tf.constant(0.5)):\n",
    "        # tf.print(tf.constant(\"coin_zoom_img_and_msk\"))\n",
    "        # tf.print(coin_zoom_img_and_msk)\n",
    "        img,msk = zoom_img_and_msk(img, msk,height = IMG_HEIGHT,width = IMG_WIDTH)\n",
    "    \n",
    "    return img,msk\n",
    "\n",
    "def load_dataset(file_paths, reshape = False,buffer_size = 1000, batch_size = 12,training = True, num_epochs = EPOCHS):\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "    dataset = tf.data.TextLineDataset(filenames=file_paths)\n",
    "    dataset = dataset.skip(1).map(parser).cache()\n",
    "    \n",
    "    # reshape\n",
    "    if reshape == True:\n",
    "        dataset = dataset.map(img_reshape)\n",
    "    \n",
    "    dataset = dataset.map(data_augmentation)\n",
    "    \n",
    "    if training == True:\n",
    "        dataset = dataset.shuffle(buffer_size =buffer_size)\n",
    "        dataset = dataset.repeat(count=num_epochs)\n",
    "    else:\n",
    "        dataset = dataset.repeat(count=1)\n",
    "        \n",
    "    dataset = dataset.batch(batch_size = batch_size,drop_remainder = False).prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "241b3f76-3fc1-4629-a06b-d13d2b358e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3be7503b-c879-47a9-9f88-307bcfa63312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/windact/cloud_detection/cloudnet-package/trainer/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/windact/cloud_detection/cloudnet-package/trainer/utils.py\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "\n",
    "smooth = 0.0000001\n",
    "\n",
    "\n",
    "def jacc_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))\n",
    "\n",
    "\n",
    "class ADAMLearningRateTracker(keras.callbacks.Callback):\n",
    "    \"\"\"It prints out the last used learning rate after each epoch (useful for resuming a training)\n",
    "    original code: https://github.com/keras-team/keras/issues/7874#issuecomment-329347949\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, end_lr):\n",
    "        super(ADAMLearningRateTracker, self).__init__()\n",
    "        self.end_lr = end_lr\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):  # works only when decay in optimizer is zero\n",
    "        optimizer = self.model.optimizer\n",
    "        # t = K.cast(optimizer.iterations, K.floatx()) + 1\n",
    "        # lr_t = K.eval(optimizer.lr * (K.sqrt(1. - K.pow(optimizer.beta_2, t)) /\n",
    "        #                               (1. - K.pow(optimizer.beta_1, t))))\n",
    "        # print('\\n***The last Actual Learning rate in this epoch is:', lr_t,'***\\n')\n",
    "        print('\\n***The last Basic Learning rate in this epoch is:', K.eval(optimizer.lr), '***\\n')\n",
    "        # stops the training if the basic lr is less than or equal to end_learning_rate\n",
    "        if K.eval(optimizer.lr) <= self.end_lr:\n",
    "            print(\"training is finished\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd63666a-d6c3-4be1-a5c8-33e67966c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93da3033-e07c-4452-8e6e-f78ea2917684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/windact/cloud_detection/cloudnet-package/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/windact/cloud_detection/cloudnet-package/trainer/model.py\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization,\\\n",
    "    Activation, Dropout\n",
    "from tensorflow import  keras\n",
    "\n",
    "\"\"\"\n",
    "Some parts borrowed from https://www.kaggle.com/cjansen/u-net-in-keras\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def bn_relu(input_tensor):\n",
    "    \"\"\"It adds a Batch_normalization layer before a Relu\n",
    "    \"\"\"\n",
    "    input_tensor = BatchNormalization(axis=3)(input_tensor)\n",
    "    return Activation(\"relu\")(input_tensor)\n",
    "\n",
    "\n",
    "def contr_arm(input_tensor, filters, kernel_size):\n",
    "    \"\"\"It adds a feedforward signal to the output of two following conv layers in contracting path\n",
    "       TO DO: remove keras.layers.add and replace it with add only\n",
    "    \"\"\"\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(input_tensor)\n",
    "    x = bn_relu(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = bn_relu(x)\n",
    "\n",
    "    filters_b = filters // 2\n",
    "    kernel_size_b = (kernel_size[0]-2, kernel_size[0]-2)  # creates a kernl size of (1,1) out of (3,3)\n",
    "\n",
    "    x1 = Conv2D(filters_b, kernel_size_b, padding='same')(input_tensor)\n",
    "    x1 = bn_relu(x1)\n",
    "\n",
    "    x1 = concatenate([input_tensor, x1], axis=3)\n",
    "    x = keras.layers.add([x, x1])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def imprv_contr_arm(input_tensor, filters, kernel_size ):\n",
    "    \"\"\"It adds a feedforward signal to the output of two following conv layers in contracting path\n",
    "    \"\"\"\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(input_tensor)\n",
    "    x = bn_relu(x)\n",
    "\n",
    "    x0 = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x0 = bn_relu(x0)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x0)\n",
    "    x = bn_relu(x)\n",
    "\n",
    "    filters_b = filters // 2\n",
    "    kernel_size_b = (kernel_size[0]-2, kernel_size[0]-2)  # creates a kernl size of (1,1) out of (3,3)\n",
    "\n",
    "    x1 = Conv2D(filters_b, kernel_size_b, padding='same')(input_tensor)\n",
    "    x1 = bn_relu(x1)\n",
    "\n",
    "    x1 = concatenate([input_tensor, x1], axis=3)\n",
    "\n",
    "    x2 = Conv2D(filters, kernel_size_b, padding='same')(x0)\n",
    "    x2 = bn_relu(x2)\n",
    "\n",
    "    x = keras.layers.add([x, x1, x2])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def bridge(input_tensor, filters, kernel_size):\n",
    "    \"\"\"It is exactly like the identity_block plus a dropout layer. This block only uses in the valley of the UNet\n",
    "    \"\"\"\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(input_tensor)\n",
    "    x = bn_relu(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = Dropout(.15)(x)\n",
    "    x = bn_relu(x)\n",
    "\n",
    "    filters_b = filters // 2\n",
    "    kernel_size_b = (kernel_size[0]-2, kernel_size[0]-2)  # creates a kernl size of (1,1) out of (3,3)\n",
    "\n",
    "    x1 = Conv2D(filters_b, kernel_size_b, padding='same')(input_tensor)\n",
    "    x1 = bn_relu(x1)\n",
    "\n",
    "    x1 = concatenate([input_tensor, x1], axis=3)\n",
    "    x = keras.layers.add([x, x1])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_exp_path(input_tensor, filters, kernel_size):\n",
    "    \"\"\"It Is only the convolution part inside each expanding path's block\n",
    "    \"\"\"\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(input_tensor)\n",
    "    x = bn_relu(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = bn_relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_exp_path3(input_tensor, filters, kernel_size):\n",
    "    \"\"\"It Is only the convolution part inside each expanding path's block\n",
    "    \"\"\"\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(input_tensor)\n",
    "    x = bn_relu(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = bn_relu(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = bn_relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def add_block_exp_path(input_tensor1, input_tensor2, input_tensor3):\n",
    "    \"\"\"It is for adding two feed forwards to the output of the two following conv layers in expanding path\n",
    "    \"\"\"\n",
    "\n",
    "    x = keras.layers.add([input_tensor1, input_tensor2, input_tensor3])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def improve_ff_block4(input_tensor1, input_tensor2 ,input_tensor3, input_tensor4, pure_ff):\n",
    "    \"\"\"It improves the skip connection by using previous layers feature maps\n",
    "       TO DO: shrink all of ff blocks in one function/class\n",
    "    \"\"\"\n",
    "\n",
    "    for ix in range(1):\n",
    "        if ix == 0:\n",
    "            x1 = input_tensor1\n",
    "        x1 = concatenate([x1, input_tensor1], axis=3)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "    for ix in range(3):\n",
    "        if ix == 0:\n",
    "            x2 = input_tensor2\n",
    "        x2 = concatenate([x2, input_tensor2], axis=3)\n",
    "    x2 = MaxPooling2D(pool_size=(4, 4))(x2)\n",
    "\n",
    "    for ix in range(7):\n",
    "        if ix == 0:\n",
    "            x3 = input_tensor3\n",
    "        x3 = concatenate([x3, input_tensor3], axis=3)\n",
    "    x3 = MaxPooling2D(pool_size=(8, 8))(x3)\n",
    "\n",
    "    for ix in range(15):\n",
    "        if ix == 0:\n",
    "            x4 = input_tensor4\n",
    "        x4 = concatenate([x4, input_tensor4], axis=3)\n",
    "    x4 = MaxPooling2D(pool_size=(16, 16))(x4)\n",
    "\n",
    "    x = keras.layers.add([x1, x2, x3, x4, pure_ff])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def improve_ff_block3(input_tensor1, input_tensor2, input_tensor3, pure_ff):\n",
    "    \"\"\"It improves the skip connection by using previous layers feature maps\n",
    "    \"\"\"\n",
    "\n",
    "    for ix in range(1):\n",
    "        if ix == 0:\n",
    "            x1 = input_tensor1\n",
    "        x1 = concatenate([x1, input_tensor1], axis=3)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "    for ix in range(3):\n",
    "        if ix == 0:\n",
    "            x2 = input_tensor2\n",
    "        x2 = concatenate([x2, input_tensor2], axis=3)\n",
    "    x2 = MaxPooling2D(pool_size=(4, 4))(x2)\n",
    "\n",
    "    for ix in range(7):\n",
    "        if ix == 0:\n",
    "            x3 = input_tensor3\n",
    "        x3 = concatenate([x3, input_tensor3], axis=3)\n",
    "    x3 = MaxPooling2D(pool_size=(8, 8))(x3)\n",
    "\n",
    "    x = keras.layers.add([x1, x2, x3, pure_ff])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def improve_ff_block2(input_tensor1, input_tensor2, pure_ff):\n",
    "    \"\"\"It improves the skip connection by using previous layers feature maps\n",
    "    \"\"\"\n",
    "\n",
    "    for ix in range(1):\n",
    "        if ix == 0:\n",
    "            x1 = input_tensor1\n",
    "        x1 = concatenate([x1, input_tensor1], axis=3)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "    for ix in range(3):\n",
    "        if ix == 0:\n",
    "            x2 = input_tensor2\n",
    "        x2 = concatenate([x2, input_tensor2], axis=3)\n",
    "    x2 = MaxPooling2D(pool_size=(4, 4))(x2)\n",
    "\n",
    "    x = keras.layers.add([x1, x2, pure_ff])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def improve_ff_block1(input_tensor1, pure_ff):\n",
    "    \"\"\"It improves the skip connection by using previous layers feature maps\n",
    "    \"\"\"\n",
    "\n",
    "    for ix in range(1):\n",
    "        if ix == 0:\n",
    "            x1 = input_tensor1\n",
    "        x1 = concatenate([x1, input_tensor1], axis=3)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "    x = keras.layers.add([x1, pure_ff])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def model_arch(input_rows=192, input_cols=192, num_of_channels=4, num_of_classes=1):\n",
    "    inputs = Input((input_rows, input_cols, num_of_channels))\n",
    "    conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "\n",
    "    conv1 = contr_arm(conv1, 32, (3, 3))\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = contr_arm(pool1, 64, (3, 3))\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = contr_arm(pool2, 128, (3, 3))\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = contr_arm(pool3, 256, (3, 3))\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = imprv_contr_arm(pool4, 512, (3, 3))\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "\n",
    "    conv6 = bridge(pool5, 1024, (3, 3))\n",
    "\n",
    "    convT7 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    prevup7 = improve_ff_block4(input_tensor1=conv4, input_tensor2=conv3, input_tensor3=conv2, input_tensor4=conv1, pure_ff=conv5)\n",
    "    up7 = concatenate([convT7, prevup7], axis=3)\n",
    "    conv7 = conv_block_exp_path3(input_tensor=up7, filters=512, kernel_size=(3, 3))\n",
    "    conv7 = add_block_exp_path(conv7, conv5, convT7)\n",
    "\n",
    "    convT8 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    prevup8 = improve_ff_block3(input_tensor1=conv3, input_tensor2=conv2, input_tensor3=conv1, pure_ff=conv4)\n",
    "    up8 = concatenate([convT8, prevup8], axis=3)\n",
    "    conv8 = conv_block_exp_path(input_tensor=up8, filters=256, kernel_size=(3, 3))\n",
    "    conv8 = add_block_exp_path(input_tensor1=conv8, input_tensor2=conv4, input_tensor3=convT8)\n",
    "\n",
    "    convT9 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    prevup9 = improve_ff_block2(input_tensor1=conv2, input_tensor2=conv1, pure_ff=conv3)\n",
    "    up9 = concatenate([convT9, prevup9], axis=3)\n",
    "    conv9 = conv_block_exp_path(input_tensor=up9, filters=128, kernel_size=(3, 3))\n",
    "    conv9 = add_block_exp_path(input_tensor1=conv9, input_tensor2=conv3, input_tensor3=convT9)\n",
    "\n",
    "    convT10 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv9)\n",
    "    prevup10 = improve_ff_block1(input_tensor1=conv1, pure_ff=conv2)\n",
    "    up10 = concatenate([convT10, prevup10], axis=3)\n",
    "    conv10 = conv_block_exp_path(input_tensor=up10, filters=64, kernel_size=(3, 3))\n",
    "    conv10 = add_block_exp_path(input_tensor1=conv10, input_tensor2=conv2, input_tensor3=convT10)\n",
    "\n",
    "    convT11 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv10)\n",
    "    up11 = concatenate([convT11, conv1], axis=3)\n",
    "    conv11 = conv_block_exp_path(input_tensor=up11, filters=32, kernel_size=(3, 3))\n",
    "    conv11 = add_block_exp_path(input_tensor1=conv11, input_tensor2=conv1, input_tensor3=convT11)\n",
    "\n",
    "    conv12 = Conv2D(num_of_classes, (1, 1), activation='sigmoid')(conv11)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0baf8abf-549a-434e-a1db-ed9bc6a26951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c36e250-917a-4882-9e68-7c4ba74b8b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/windact/cloud_detection/cloudnet-package/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/windact/cloud_detection/cloudnet-package/trainer/task.py\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping,TensorBoard\n",
    "\n",
    "from trainer.utils import ADAMLearningRateTracker, jacc_coef\n",
    "from trainer.model import model_arch\n",
    "\n",
    "# logger\n",
    "model_logger = logging.getLogger(__name__)\n",
    "model_logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')\n",
    "\n",
    "model_logger_file_handler = logging.FileHandler('model.log')\n",
    "model_logger_file_handler.setFormatter(formatter)\n",
    "\n",
    "model_logger.addHandler(model_logger_file_handler)\n",
    "\n",
    "\n",
    "\n",
    "def _parse_arguments(argv):\n",
    "    \"\"\"Parses command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--train_data_path',\n",
    "        help='train data path',\n",
    "        type=str, default=\"/home/jupyter/cloud_detection/data/train_data.csv\")\n",
    "    parser.add_argument(\n",
    "        '--val_data_path',\n",
    "        help='validation data path',\n",
    "        type=str, default=\"/home/jupyter/cloud_detection/data/val_data.csv\")\n",
    "    parser.add_argument(\n",
    "        '--batch_size',\n",
    "        help='model batch size',\n",
    "        type=int, default=12)\n",
    "    parser.add_argument(\n",
    "        '--epochs',\n",
    "        help='The number of epochs to train',\n",
    "        type=int, default=10)\n",
    "    parser.add_argument(\n",
    "        '--random_state',\n",
    "        help='random state',\n",
    "        type=int, default=42)\n",
    "    parser.add_argument(\n",
    "        '--starting_learning_rate',\n",
    "        help='starting learning rate',\n",
    "        type=float, default=1e-4)\n",
    "    parser.add_argument(\n",
    "        '--end_learning_rate',\n",
    "        help='end learning rate',\n",
    "        type=float, default=1e-8)\n",
    "    parser.add_argument(\n",
    "        '--input_rows',\n",
    "        help='input image input_rows',\n",
    "        type=int, default=192)\n",
    "    parser.add_argument(\n",
    "        '--input_cols',\n",
    "        help='input image input_rows',\n",
    "        type=int, default=192)\n",
    "    parser.add_argument(\n",
    "        '--patience',\n",
    "        help='patience for early_s_patience.ReduceLROnPlateau',\n",
    "        type=int, default=15)\n",
    "    parser.add_argument(\n",
    "        '--decay_factor',\n",
    "        help='decay_factor for tensorflow.keras.callbacks.ReduceLROnPlateau',\n",
    "        type=float, default=0.7)\n",
    "    parser.add_argument(\n",
    "        '--experiment_name',\n",
    "        help='experiment_name',\n",
    "        type=str, default=\"cloudnet\")\n",
    "    parser.add_argument(\n",
    "        '--early_s_patience',\n",
    "        help='tensorflow.keras.callbacks.EarlyStopping patience',\n",
    "        type=int, default=20)\n",
    "    parser.add_argument(\n",
    "        '--num_of_channels',\n",
    "        help='num_of_channels',\n",
    "        type=int, default=16)\n",
    "    parser.add_argument(\n",
    "        '--num_of_classes',\n",
    "        help='num_of_classes',\n",
    "        type=int, default=4)\n",
    "    parser.add_argument(\n",
    "        '--reshape',\n",
    "        help='reshape image and mask to the sampe shape',\n",
    "        type=bool, default=True)\n",
    "    parser.add_argument(\n",
    "        '--quick_test',\n",
    "        help='run the model on a smaler sample',\n",
    "        type=bool, default=False)\n",
    "    parser.add_argument(\n",
    "        '--train_resume',\n",
    "        help='resume train or not',\n",
    "        type=bool, default=False)\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help='Directory where to save the given model',\n",
    "        type=str, default='cloud_detection_models/')\n",
    "    \n",
    "    return parser.parse_known_args(argv)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Get the arguments\n",
    "    args = _parse_arguments(sys.argv[1:])[0]\n",
    "\n",
    "    #BATCH_SIZE = args.batch_size\n",
    "    # SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "    # RANDOM_STATE = args.random_state\n",
    "    # AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    TRAIN_DATA_PATH = args.train_data_path\n",
    "    VAL_DATA_PATH = args.val_data_path\n",
    "\n",
    "    #quick_test = args.quick_test\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    experiment_name = f\"{args.experiment_name}_{current_time}\"\n",
    "    \n",
    "    ROOT_DIR = Path.cwd().resolve()\n",
    "    MODEL_DIR = ROOT_DIR / \"models\"\n",
    "    TRAIN_DIR = MODEL_DIR / \"train\"\n",
    "    TEST_DIR = MODEL_DIR / \"test\"\n",
    "    EXP_DIR = TRAIN_DIR / experiment_name\n",
    "    \n",
    "    ORIGINAL_MODEL_WEIGHT_PATH = (MODEL_DIR / \"original_weights\") / \"Cloud-Net_trained_on_38-Cloud_training_patches.h5\" # not implemented\n",
    "\n",
    "    folders = [MODEL_DIR,TRAIN_DIR,TEST_DIR,EXP_DIR]\n",
    "    for folder in folders:\n",
    "        if not folder.exists():\n",
    "            folder.mkdir(parents = False,exist_ok= True)\n",
    "\n",
    "    MODEL_WEIGHTS_PATH = ROOT_DIR/\"model_weights\"\n",
    "    if not MODEL_WEIGHTS_PATH.exists():\n",
    "        MODEL_WEIGHTS_PATH.mkdir()\n",
    "\n",
    "    weights_path = MODEL_WEIGHTS_PATH / \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    random_state = args.random_state\n",
    "\n",
    "    # hparams\n",
    "    # starting_learning_rate = args.starting_learning_rate\n",
    "    # end_learning_rate = args.end_learning_rate\n",
    "    # epochs = args.epochs # just a huge number. The actual training should not be limited by this value\n",
    "    # #val_ratio = 0.2\n",
    "    # patience = args.patience\n",
    "    # decay_factor = args.decay_factor\n",
    "    # experiment_name = args.experiment_name\n",
    "    # early_s_patience = args.early_s_patience\n",
    "\n",
    "    # params\n",
    "    input_rows = args.input_rows\n",
    "    input_cols = args.input_cols\n",
    "    # img_shape = (input_rows,input_cols)\n",
    "    num_of_channels = args.num_of_channels\n",
    "    num_of_classes = args.num_of_classes\n",
    "    reshape = args.reshape\n",
    "\n",
    "    # hparams\n",
    "    batch_size = args.batch_size\n",
    "    starting_learning_rate = args.starting_learning_rate\n",
    "    end_learning_rate = args.end_learning_rate\n",
    "    max_num_epochs = args.epochs # just a huge number. The actual training should not be limited by this value\n",
    "    patience = args.patience\n",
    "    decay_factor = args.decay_factor\n",
    "\n",
    "    early_s_patience = args.early_s_patience\n",
    "    train_resume = args.train_resume\n",
    "    \n",
    "    # log\n",
    "    model_logger.info(\"All parameters have been paresed\")\n",
    "    \n",
    "    # datasets\n",
    "    train_dataset = load_dataset(file_paths= TRAIN_DATA_PATH, training = True,reshape= reshape, num_epochs=max_num_epochs)\n",
    "    val_dataset = load_dataset(file_paths= VAL_DATA_PATH, training = False,reshape= reshape)\n",
    "\n",
    "    # Model\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    model_logger.info('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = model_arch(input_rows=input_rows,\n",
    "                                           input_cols=input_cols,\n",
    "                                           num_of_channels=num_of_channels,\n",
    "                                           num_of_classes=num_of_classes)\n",
    "        \n",
    "        model.compile(optimizer=Adam(learning_rate=starting_learning_rate), loss=jacc_coef, metrics=[jacc_coef])\n",
    "    # model.summary()\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True)\n",
    "    lr_reducer = ReduceLROnPlateau(factor=decay_factor, cooldown=0, patience=patience, min_lr=end_learning_rate, verbose=1)\n",
    "    csv_logger = CSVLogger(EXP_DIR / '_log_1.log')\n",
    "    tensorboard = TensorBoard(log_dir= EXP_DIR / 'logs', histogram_freq=0, write_graph=True,write_images=False, write_steps_per_second=False,\n",
    "                                   update_freq='epoch',profile_batch=0, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
    "\n",
    "    if train_resume:\n",
    "        model.load_weights(ORIGINAL_MODEL_WEIGHT_PATH)\n",
    "         model_logger.info(\"\\nTraining resumed...\")\n",
    "    else:\n",
    "         model_logger.info(\"\\nTraining started from scratch... \")\n",
    "\n",
    "    model_logger(\"Experiment name: \", experiment_name)\n",
    "    model_logger(\"Input image size: \", (input_rows, input_cols))\n",
    "    model_logger(\"Number of input spectral bands: \", num_of_channels)\n",
    "    model_logger(\"Learning rate: \", starting_learning_rate)\n",
    "    model_logger(\"# Epochs: \", max_num_epochs)\n",
    "    model_logger(\"Batch size: \", batch_size, \"\\n\")\n",
    "    \n",
    "    model.fit(train_dataset,validation_data = val_dataset,epochs = max_num_epochs,verbose = 1,\n",
    "             callbacks=[model_checkpoint, lr_reducer, ADAMLearningRateTracker(end_learning_rate), csv_logger,tensorboard])\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84251404-270b-472f-887a-0661ca798c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a0310-1b6e-4102-aeba-a9751a15f1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b1719-60a2-40c0-a27f-dec35d8d8f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d5a17-f57a-499e-89bc-eafb986aafab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43b297-57a0-456f-84dd-b735e71ef456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc7116-65e0-4509-a925-811a7e8509e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_rows = args.input_rows\n",
    "# in_cols = args.input_cols\n",
    "# num_of_channels = args.num_of_channels\n",
    "# num_of_classes = args.num_of_classes\n",
    "# starting_learning_rate = args.starting_learning_rate\n",
    "# end_learning_rate = args.end_learning_rate\n",
    "# max_num_epochs = 2  # just a huge number. The actual training should not be limited by this value\n",
    "# patience = args.patience\n",
    "# decay_factor = args.decay_factor\n",
    "# batch_size = args.batch_size\n",
    "# early_s_patience = args.early_s_patience\n",
    "# current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "# experiment_name = f\"{args.experiment_name}_{current_time}\"\n",
    "# # max_bit = 65535  # maximum gray level in landsat 8 images\n",
    "# weights_path = EXP_DIR / \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "# train_resume = False\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
